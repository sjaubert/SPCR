---
title: "Bachelor - Tests Statistique"
author: "S. Jaubert"
date: "`r format(Sys.time(), ' %d %B %Y')`"
output:
  html_document: default
  pdf_document: 
    latex_engine: xelatex
---

###### Les exemples sont tirés du fascicule : D:\\OneDrive - CFAI Centre\\Bachelor\\Test statistique\\App\_test-stat-R.pdf

# Z-test

On considère un échantillon de taille $n$, $X_{1}, X_{2},..., X_{n}$ avec 
$X_{i} \hookrightarrow \mathcal{N}(\mu;\sigma)$ et un risque $\alpha$ 

* si l'on teste $H_{0} : \mu=m_{0}$ (Test bilatéral)

La statistique de test sous l'hypothèse nulle est :

\[z=\sqrt{n} \frac{\bar{X_{n}}-m_{0}}{\sigma}\] qui suit une loi normale $\mathcal{N}(0;1)$

Si $\displaystyle |z|$ , la réalisation de la statistique de test, est supérieur au quantile d'ordre $1-\frac{\alpha}{2}$ alors on rejette l'hypothèse nulle.

* Si l'on teste $\displaystyle H_{0}:m\leqslant m_{0}$

Si $\displaystyle z$ est supérieur au quantile d'ordre $\displaystyle 1-\alpha$ de la loi $\displaystyle \mathcal {N}(0,1)$ alors on rejette l'hypothèse nulle.

* Si l'on teste $\displaystyle H_{0}:m\geqslant m_{0}$
Si $\displaystyle z$ est inférieur au quantile d'ordre $\displaystyle \alpha$  de la loi $\displaystyle \mathcal {N}(0,1)$ alors on rejette l'hypothèse nulle.

Remarque : si l'on note $\displaystyle \upsilon_{\alpha}$ le quantile d'ordre $\displaystyle \alpha$  de la loi $\displaystyle \mathcal{N}(0,1)$, alors on a l'égalité $\displaystyle \upsilon _{\alpha }=-\upsilon _{1-\alpha }$





#### **Exemple 1 page 13**

```{r}
x<-c(6.47,7.02,7.15,7.22,7.44,6.99,7.47,7.61,
     7.32,7.22,7.52,6.92,7.28,6.69,7.24,7.19,
     6.97,7.52,6.22,7.13,7.32,7.67,7.24,6.21)
n<-length(x)
```

D'après l'énoncé nous avons :
$X\hookrightarrow \mathcal{N}(\mu;\sigma=0.38)$

et nous savons que 
$\bar{X}\hookrightarrow \mathcal{N}(\mu;\frac{\sigma}{\sqrt{n}})$

Nous posons :

$H_{0} : \mu=7.3$

$H_{1} : \mu\neq7.3$

Moyenne observée :

```{r}
(mo<-mean(x))
```

Nous connaissant l'écart-type $\sigma=0.38$, nous allons faire un test Z

Sous $H_{0}$ on cherche $h$ tel que :
$Pr(7.3-h< \bar{X} < 7.3+h) = 1- \alpha \Leftrightarrow Pr(\bar{X} < 7.3+h) = 1-\frac{\alpha}{2}$

Pour $\alpha=0.05$, on a : 
$\prod \left ( \frac{h}{\frac{\sigma}{\sqrt{n}}} \right )=\prod \left ( t_{0.975} \right )$

Soit :

```{r}
(h<-qnorm(0.975)*0.38/sqrt(n))
```

Nous devrions avoir dans 95% des cas (si on est bien sous $H_{0}$) :

$\overline{X} \in \left [ 7.3-h ; 7.3+h \right ]=[7.14 ;7.45]$

Or nous observons que $mo=7.126 \neq [7.14 ;7.45]$

La probabilité d'observer ( sous $H_{0}$) une valeur aussi lointaine est (d'un seul côté) :
```{r}
pnorm(mo,7.3,0.38/sqrt(n))
```

Soit une p-value de (on multiplie par 2 car le test est bilatéral) :

```{r}
2*pnorm(mo,7.3,0.38/sqrt(n))
```

Retrouvons ces résultats directement avec R :


```{r}
library(TeachingDemos) #librairie pour effectuer un test Z
```


```{r}
z.test(x,mu = 7.3,stdev = 0.38)
```

Nous retrouvons bien la p-value, la valeur z est, en nombre d'écart-type, la distance qui sépare $\mu$ de la valeur observée

```{r}
(mo-7.3)/(0.38/sqrt(n))
```

Ainsi, on peut affirmer que le fournisseur ne respecte pas ses engagements avec un risque de se tromper de 2.6 chances sur 100

# t-test

$\sigma$ population inconnu

on remplace sa variance $σ^{2}$ par son estimateur sans biais

$\displaystyle S_{n-1}^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\overline{X}_{n})^{2}$

La statistique de test sous l'hypothèse nulle est :

\[z=\sqrt{n} \frac{\bar{X_{n}}-m_{0}}{S_{n-1}}\] qui suit alors une loi de Student à n – 1 degrés de liberté sous l'hypothèse nulle (c'est le théorème de Cochran).

#### **Exemple 2 page 14**


```{r warning=FALSE}
x2<-c(10.1,9.8,10.2,10.3,10.4,9.8,9.9,10.4,10.2,9.5,10.4,9.6)
```

La statistique $t_{obs}$ est :
```{r}
(t_obs<-(mean(x2)-10)*sqrt(length(x2))/sd(x2))
```

La probabilité d'observer une telle valeur est :
```{r}
pt(t_obs,df = 11,lower.tail = F)
```

Nous pouvons retrouver ce résultat très simplement par :

```{r}
 t.test(x2,mu = 10,alternative = "greater")
```

Nous n'avons donc aucune raison de rejeter l'hypothèse nulle

#### **Exemple 3 page 15**
Nous observons comme moyenne :
```{r}
x<-c(232,277,235,245,250,268,256,245)
(mean(x)->mo)
```

L'hypothèse nulle $H_{0} : mu = 276$

La statistique de test est $t_{0} :$
```{r}
(to<-(mo-276)*sqrt(8)/sd(x))

```


Pour obtenir la p-value :
```{r}
pt(to,df = 7)*2
```



Avec la fonction t-test nous retrouverons ces valeurs :
```{r}
t.test(x = x,mu = 276)
```

Observer une telle valeur mo sous $H_{0}$ est donc très peu probable, nous rejetterons cette hypothèse.

#### **Exemple 4 page 16**

Soit $p$ la proportion inconnue de haricots fins.

On pose $H_{0} : p=0.25$ contre $H_{1} : p \neq 0.25$

On a pour fréquence observée $fo=118/400=0.295$

La p-value est de :
```{r}
pnorm(0.295,0.25,sd = sqrt(0.25*0.75/400),lower.tail = F)*2
```

Si on utilise le test 1-prop-Z-Test de R, on retrouve la même chose :
```{r}
prop.test(118,400,0.25,correct = F,conf.level = 0.95)
```

Le $X^{2}$ se retrouve par :
```{r}
(0.295-0.25)/sqrt(0.25*0.75/400)->X
X^2
```

Comme p-value $< 0.05$, on peut affirmer, au risque 5%, que le producteur a tort.



# Tests d'homogénéité


#### **Exemple 1 page 20**

```{r}
X1<-c(106.7,107.02,107.13,107.22,107.41,106.39,107.47,107.61,107.38,107.22)
X2<-c(107.68,106.69,107.24,107.69,106.97,107.52,106.22,107.23,107.32)
```

On a : 
$X_{1}\hookrightarrow \mathcal{N}(\mu_{1};\sigma_{1}=1.3)$ et 
$X_{2}\hookrightarrow \mathcal{N}(\mu_{2};\sigma_{2}=0.9)$

Soit l'hypothèse nulle $H_{0}:\mu_{1}=\mu_{2}$ au risque $\alpha = 0.05$

Alors sous $H_{0}$, $D=\bar{X_{1}}-\bar{X_{2}}\hookrightarrow \mathcal{N}(0;\sqrt{\frac{1.3^{2}}{10}+\frac{0.9^{2}}{9}})$


```{r}
(h<-qnorm(0.975)*sqrt(1.3^2/10+0.9^2/9))
```

Et $D\in [-0.997;0.997]$ dans 95% des cas.

```{r}
(D_obs<-mean(X1)-mean(X2))
```
D_obs est bien dans l'intervalle nous ne pouvons rejeter l'hypothèse nulle, de plus la probabilité d'observer une telle différence est :
```{r}
(p_valeur<-pnorm(-0.01833333,mean = 0,sd = sqrt(1.3^2/10+0.9^2/9))*2)
```



Avec la fonction mean_test2 de R, on retrouvera directement la même chose :

```{r}
library(OneTwoSamples)
mean_test2(X1,X2,sigma = c(1.3,0.9))
```

#### **Exemple 2 page 21**

On considère deux lots de tasses et on souhaite comparer la solidité de ceux-ci. Pour chacun des deux lots, on dispose d’un échantillon de 10 tasses et on mesure la résistance de chacune d’entre eux. Les résultats sont :

* pour le premier échantillon :
```{r}
X1<-c(31.70,31.98,32.24,32.35,31.18,32.19,32.63,31.19,31.54,31.89)

```

* pour le deuxième échantillon :

```{r}
X2<-c(31.61,31.10,31.20,31.11,32.66,31.15,31.71,31.22,31.16,31.21)
```


Peut-on affirmer que ces deux échantillons ne proviennent pas de la même production ?






# Tests d'indépendance

Voir cours page 31 ou ici : [https://sjaubert.github.io/SPCR/Test_du_Khi2.html ](https://sjaubert.github.io/SPCR/Test_du_Khi2.html)


#### **Exemple page 33**

```{r}
A<-matrix(c(50,47,56,5,14,8),nrow = 2,byrow = T)
rownames(A)<-c("Brillants","Médiocres")
colnames(A)<-c("A","B","C")
addmargins(A)
```
Détails du calcul de la matrice théorique :

```{r}
V_th<-c()
for (i in 1:2){
  for (j in 1:3){
    V_th<-c(V_th,sum(A[i,])*sum(A[,j])/sum(A))
  }
  
}
(A_th<-matrix(V_th,nrow = 2,byrow = T))
```

Que l'on retrouve avec :

```{r}
chisq.test(A)$expected
```

La statistique du $\chi^{2}$ se calcule :

```{r}
(chi2_obs <-(50-46.75)^2/46.75+(47-51.85)^2/51.85+(56-54.4)^2/54.4+(5-8.25)^2/8.25+(14-9.15)^2/9.15+(8-9.6)^2/9.6)
```

Que l'on retrouve facilement avec :
```{r}
chisq.test(A)$statistic
```

Et la p-value (probabilité d'observer une valeur aussi extrême) se détermine par :
```{r}
pchisq(q = 4.844394 ,df = 2,lower.tail = F)
```

Enfin nous pouvons avoir tous ces résultats directement par :

```{r}
chisq.test(A)
```

# Tests d'indépendance cas avec des caractères quantitatifs

Soient X et Y deux caractères quantitatifs.

On souhaite affirmer à partir des données observées que X et Y ne sont pas indépendants.

On considère alors l'hypothèse :

* $H_{0}$ : "X et Y sont indépendants"

On fait l'hypothèse que si dépendance il y a, alors elle est linéaire, donc :
$H_{0}$ : "X et Y sont indépendants $<=> \rho =0$

On démontre que sous $H_{0}$, la statistique :
\[ T=\frac{r}{\sqrt{\frac{1-r^{2}}{n-2}}}\] suit une loi de Student à $(n-2)$ degrés de liberté.

La p-value associée au test de nullité du coefficient de corrélation est :

\[ \mathbb{P}\left ( \left | T \right | \geq \left | t_{obs} \right |\right )\]


#### **Exemple page 36**

Sur 14 familles composées d’un père et d’un fils, on examine le QI du père et le QI du fils. Les résultats sont :
```{r}
Qp<-c(121,142,108,111,97,139,131,90,115,107,124,103,115,151)
Qf<-c(102,138,126,133,95,146,115,100,142,105,130,120,109,123)
```

Peut-on affirmer qu’il y a une liaison significative entre le QI du père et le QI du
fils ?

$t_{obs}=\frac{r}{\sqrt{\frac{1-r^{2}}{n-2}}}$

```{r}
n<-length(Qp)
r<-cor(Qp,Qf)
(t_obs<-r/sqrt((1-r^2)/(n-2)))
```

Soit une p-value :
```{r}
(p_value<-2*pt(t_obs,df = n-2,lower.tail = F))
```

Résultats que l'on a directement avec :

```{r}
cor.test(Qp,Qf)
```

On peut donc affirmer qu'il y a une liaison significative entre le QI du père et celui du fils.


#### **Exercice 10 page 42**
```{r}
chequiers<-read.table(file = "https://sjaubert.github.io/SPCR/chequiers.txt",header = T)
colnames(chequiers)<-c("Interdit","age")
```

```{r}
(table(chequiers)->tab)

```

Essayez de comprendre les résultats suivants :

```{r}
(chisq.test(tab)->res)
res$statistic
res$expected
```

